{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terrain Correction Calculation\n",
    "\n",
    "Outline:\n",
    " - Read in tiff of dem\n",
    " - Resample DEM to 59 x 59 m to reduce computation time\n",
    " - Create prisms model of DEM\n",
    " - Read in csv file of PPK positions\n",
    " - Sample the DEM at the measurment locations\n",
    " - Calculate the gravity anomaly from the model at the measurement locations, with the sampled elevation from the DEM\n",
    " - Find the difference between bouguer slab correction and model results with sampled elevation from DEM - this is the terrain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.interpolate import  interp1d #RegularGridInterpolator,, RectBivariateSpline\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray\n",
    "# import fiona\n",
    "# import rasterio.mask\n",
    "import pandas as pd\n",
    "# import verde as vd\n",
    "# import geopandas as gpd\n",
    "import time\n",
    "# from shapely.geometry import *\n",
    "# import rasterio as rs\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "# import pyvista as pv\n",
    "import harmonica as hm\n",
    "from shapely import geometry\n",
    "\n",
    "#from discretize.utils import mkvc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in the data measurement locations\n",
    "profile4 = pd.read_csv('Data/prof4_meas.csv')\n",
    "profile7a = pd.read_csv('Data/prof7a_meas.csv')\n",
    "longa = pd.read_csv('Data/longa_meas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_raster(file): #create a function to read in the dem in tif format and convert it to an xarray which is used by harmonica\n",
    "    #note function returns a dataArray and a Dataset which are different things - we use the dataArray - and also an array of x,y,z values\n",
    "    geotiff_da = rioxarray.open_rasterio(file)\n",
    "    geotiff_ds = geotiff_da.to_dataset('band') # Covert our xarray.DataArray into a xarray.Dataset\n",
    "    geotiff_ds = geotiff_ds.rename({1: 'topo'}) # Rename the variable to a more useful name in the dataset\n",
    "\n",
    "    geo_tiff_topo = geotiff_da[0] # in the dataArray select just the first variable which is the topography\n",
    "\n",
    "    [x_topo, y_topo] = np.meshgrid(geo_tiff_topo.x.values, geo_tiff_topo.y.values) # the x and y values are read in as a single array for each and we want to create a grid of all values\n",
    "    z_topo = geo_tiff_topo.values # defining the z component as the topography\n",
    "\n",
    "    topo_xyz = np.c_[x_topo.ravel(), y_topo.ravel(), z_topo.ravel()] # we combine the x,y and z information into one array to be returned as a standard array\n",
    "\n",
    "    topo_xr = xr.DataArray(geo_tiff_topo.values, # create the DataArray\n",
    "    coords={'y': y_topo[:,0],'x': x_topo[0,:]}, \n",
    "    dims=[\"y\", \"x\"])\n",
    "\n",
    "    return topo_xr #returns the dataset, numpy array and dataArray\n",
    "\n",
    "surf_inside = open_raster('Model_components/surf_inside.tif')\n",
    "bed_outside = open_raster('Model_components/bed_outside.tif')\n",
    "surf_xr_resamp = open_raster('Model_components/surf_xr_resamp.tif')\n",
    "mask_geom_small = np.loadtxt('Model_components/mask_geom_small.csv', delimiter=',')\n",
    "mask_rock_small = np.loadtxt('Model_components/mask_rock_small.csv', delimiter=',')\n",
    "band_xr =  open_raster('Model_components/band_xr.tif')\n",
    "dist_norm_xr = open_raster('Model_components/dist_norm_xr.tif')\n",
    "mod_xr = open_raster('Model_components/mod_xr.tif')\n",
    "center_points = pd.read_csv('Model_components/center_points_250m_nad83.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create simple shape function\n",
    "dist_norm = np.arange(0,1.1,0.1)\n",
    "#uncomment shape desired\n",
    "y =  dist_norm**1/4 #V-shape\n",
    "# y =  dist_norm**2/4 #U-shape\n",
    "# y =  dist_norm**2.8/4 #wide-U-shape\n",
    "parab_y = ((max(y) - y)/max(y)) #rearrange to make parabola to required function\n",
    "parab_y = parab_y[::-1]\n",
    "shape_func = interp1d(dist_norm, parab_y) #create shape function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply function within model area\n",
    "thick_normal_xr = dist_norm_xr.copy()\n",
    "for i in range(-1, 2):\n",
    "    if i == 0:\n",
    "        thick_normal_xr = thick_normal_xr.where(mod_xr != i, 0)\n",
    "    if i == 1:\n",
    "        thick_normal_xr = thick_normal_xr.where(mod_xr != i, shape_func(dist_norm_xr.where(mod_xr == i)))\n",
    "\n",
    "x_dp = xr.DataArray(center_points['xcoord']) #turn the x and y into dataArrays so they can be used to sample the dem\n",
    "y_dp = xr.DataArray(center_points['ycoord'])\n",
    "center_points['thick_norm'] = thick_normal_xr.sel(x=x_dp, y=y_dp, method='nearest') #extract the thick norm values along the inversion points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outside Gravity Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate contribution from area outside model area\n",
    "density = bed_outside.copy() # create a density data array\n",
    "density.values[:] = 917 - 2700  # replace every value for the density of the topography\n",
    "prisms = hm.prism_layer( # this is where we create the model of the topography, by creating a layer of prisms with varying elevation based on the dem\n",
    "    (bed_outside.x.values, bed_outside.y.values),\n",
    "    surface=bed_outside,\n",
    "    reference=surf_xr_resamp,\n",
    "    properties={\"density\": density},\n",
    ")\n",
    "\n",
    "# meas_grav['outer_grav'] = prisms.prism_layer.gravity((meas_grav['x_8N'], meas_grav['y_8N'], meas_grav['Elev']), field=\"g_z\")\n",
    "\n",
    "profile4['outer_grav'] = prisms.prism_layer.gravity((profile4['x_8N'], profile4['y_8N'], profile4['Elev']), field=\"g_z\")\n",
    "profile7a['outer_grav'] = prisms.prism_layer.gravity((profile7a['x_8N'], profile7a['y_8N'], profile7a['Elev']), field=\"g_z\")\n",
    "longa['outer_grav'] = prisms.prism_layer.gravity((longa['x_8N'], longa['y_8N'], longa['Elev']), field=\"g_z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up points to be be inverted, starting model and density\n",
    "param_start = np.ones_like(center_points['distance'])*1550\n",
    "\n",
    "density_model = surf_inside.copy()\n",
    "density_model.values[:] = 917 - 2700\n",
    "meas_points = longa.copy()\n",
    "g_meas_c10 = longa.boug_anom_2700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inversion functions\n",
    "#define inversion function - takes parameters which is bed elevation\n",
    "def model(parameters0):\n",
    "    params_xr = surf_inside.copy()\n",
    "    param_norm = parameters0/center_points['thick_norm']\n",
    "    for i in range(len(center_points)):\n",
    "        dist_band = center_points['distance'].iloc[i]\n",
    "        params_xr = params_xr.where(band_xr != dist_band, thick_normal_xr*param_norm[i])\n",
    "    #final edit to make sure areas outside polygon are set to 0 thickness\n",
    "    params_xr = params_xr.where(mask_geom_small == 1, 0)\n",
    "    params_xr = params_xr.where(mask_rock_small == 0, 0)\n",
    "\n",
    "    prisms_glacier = hm.prism_layer(\n",
    "        (params_xr.x.values, params_xr.y.values),\n",
    "        surface=surf_inside - params_xr,\n",
    "        reference=surf_inside,\n",
    "        properties={\"density\": density_model},\n",
    "    )\n",
    "\n",
    "    # g_sed_basin = prisms_glacier.prism_layer.gravity((meas_grav.x_8N, meas_grav.y_8N, meas_grav.Elev), field=\"g_z\")\n",
    "    g_inside = prisms_glacier.prism_layer.gravity((longa.x_8N, longa.y_8N, longa.Elev), field=\"g_z\")\n",
    "    g_inside_p4 = prisms_glacier.prism_layer.gravity((profile4['x_8N'], profile4['y_8N'], profile4['Elev']), field=\"g_z\")\n",
    "    g_tot = (g_inside - g_inside_p4[0]) + (longa['outer_grav'] - profile4['outer_grav'].iloc[0])\n",
    "\n",
    "    return g_tot\n",
    "\n",
    "def misfit(meas, model): #takes the measurements, the model, optionally start and end index of section\n",
    "    e_1 = (2*np.sum(abs(meas - model)))/(np.sum(abs(meas - model)) +  np.sum(abs(meas + model))) #sum of differences\n",
    "    return e_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate tolerance\n",
    "Ugrs = longa['error'] \n",
    "test_meas = g_meas_c10\n",
    "noise_misfit = []\n",
    "for i in range(100):\n",
    "    test_noise = test_meas + np.random.normal(0, Ugrs, len(test_meas))\n",
    "    noise_misfit.append(misfit(test_meas, test_noise))\n",
    "\n",
    "tolerance = np.mean(noise_misfit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set max and min limits\n",
    "p_min = param_start -600  \n",
    "p_max = param_start+400 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 110\u001b[0m\n\u001b[1;32m    107\u001b[0m     params_smoothed[i_up:] \u001b[38;5;241m=\u001b[39m params_smoothed[i_up\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    109\u001b[0m accept \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#reset acceptance flag\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m M_new \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_smoothed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m#calulate anomaly with new parameter values\u001b[39;00m\n\u001b[1;32m    111\u001b[0m E_new \u001b[38;5;241m=\u001b[39m misfit(g_meas_c10[mp_i], M_new[mp_i]) \u001b[38;5;66;03m#calculate new error\u001b[39;00m\n\u001b[1;32m    112\u001b[0m delta_E \u001b[38;5;241m=\u001b[39m E_new \u001b[38;5;241m-\u001b[39m E_old \u001b[38;5;66;03m#check compared to old error\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m, in \u001b[0;36mmodel\u001b[0;34m(parameters0)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dist_points)):\n\u001b[1;32m      6\u001b[0m     dist_band \u001b[38;5;241m=\u001b[39m dist_points[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39miloc[i]\n\u001b[0;32m----> 7\u001b[0m     params_xr \u001b[38;5;241m=\u001b[39m \u001b[43mparams_xr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist_xr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdist_band\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthick_normal_xr\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparam_norm\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#final edit to make sure areas outside polygon are set to 0 thickness\u001b[39;00m\n\u001b[1;32m      9\u001b[0m params_xr \u001b[38;5;241m=\u001b[39m params_xr\u001b[38;5;241m.\u001b[39mwhere(mask_geom_small \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/common.py:1116\u001b[0m, in \u001b[0;36mDataWithCoords.where\u001b[0;34m(self, cond, other, drop)\u001b[0m\n\u001b[1;32m   1113\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39misel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers)\n\u001b[1;32m   1114\u001b[0m     cond \u001b[38;5;241m=\u001b[39m cond\u001b[38;5;241m.\u001b[39misel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mindexers)\n\u001b[0;32m-> 1116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/ops.py:177\u001b[0m, in \u001b[0;36mwhere_method\u001b[0;34m(self, cond, other)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;66;03m# alignment for three arguments is complicated, so don't support it yet\u001b[39;00m\n\u001b[1;32m    176\u001b[0m join \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m other \u001b[38;5;129;01mis\u001b[39;00m dtypes\u001b[38;5;241m.\u001b[39mNA \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexact\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_ufunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mduck_array_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwhere_method\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcond\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_join\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallowed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/computation.py:1196\u001b[0m, in \u001b[0;36mapply_ufunc\u001b[0;34m(func, input_core_dims, output_core_dims, exclude_dims, vectorize, join, dataset_join, dataset_fill_value, keep_attrs, kwargs, dask, output_dtypes, output_sizes, meta, dask_gufunc_kwargs, *args)\u001b[0m\n\u001b[1;32m   1194\u001b[0m \u001b[38;5;66;03m# feed DataArray apply_variable_ufunc through apply_dataarray_vfunc\u001b[39;00m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, DataArray) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[0;32m-> 1196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapply_dataarray_vfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables_vfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1199\u001b[0m \u001b[43m        \u001b[49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_attrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_attrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1204\u001b[0m \u001b[38;5;66;03m# feed Variables directly through apply_variable_ufunc\u001b[39;00m\n\u001b[1;32m   1205\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(a, Variable) \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m args):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/computation.py:287\u001b[0m, in \u001b[0;36mapply_dataarray_vfunc\u001b[0;34m(func, signature, join, exclude_dims, keep_attrs, *args)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataarray\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataArray\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 287\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[43mdeep_align\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraise_on_invalid\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    291\u001b[0m objs \u001b[38;5;241m=\u001b[39m _all_of_type(args, DataArray)\n\u001b[1;32m    293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keep_attrs \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/alignment.py:848\u001b[0m, in \u001b[0;36mdeep_align\u001b[0;34m(objects, join, copy, indexes, exclude, raise_on_invalid, fill_value)\u001b[0m\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    846\u001b[0m         out\u001b[38;5;241m.\u001b[39mappend(variables)\n\u001b[0;32m--> 848\u001b[0m aligned \u001b[38;5;241m=\u001b[39m \u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mtargets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    851\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    852\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    853\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    854\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    855\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m position, key, aligned_obj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(positions, keys, aligned):\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mis\u001b[39;00m no_key:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/alignment.py:785\u001b[0m, in \u001b[0;36malign\u001b[0;34m(join, copy, indexes, exclude, fill_value, *objects)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03mGiven any number of Dataset and/or DataArray objects, returns new\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;124;03mobjects with aligned indexes and dimension sizes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    775\u001b[0m \n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    777\u001b[0m aligner \u001b[38;5;241m=\u001b[39m Aligner(\n\u001b[1;32m    778\u001b[0m     objects,\n\u001b[1;32m    779\u001b[0m     join\u001b[38;5;241m=\u001b[39mjoin,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    783\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m    784\u001b[0m )\n\u001b[0;32m--> 785\u001b[0m \u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malign\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m aligner\u001b[38;5;241m.\u001b[39mresults\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/alignment.py:578\u001b[0m, in \u001b[0;36mAligner.align\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverride_indexes()\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/alignment.py:555\u001b[0m, in \u001b[0;36mAligner.reindex_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreindex_all\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 555\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    556\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatching_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatching_indexes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjects_matching_indexes\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/alignment.py:556\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    554\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreindex_all\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    555\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(\n\u001b[0;32m--> 556\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmatching_indexes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    557\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m obj, matching_indexes \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[1;32m    558\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjects_matching_indexes\n\u001b[1;32m    559\u001b[0m         )\n\u001b[1;32m    560\u001b[0m     )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/alignment.py:542\u001b[0m, in \u001b[0;36mAligner._reindex_one\u001b[0;34m(self, obj, matching_indexes)\u001b[0m\n\u001b[1;32m    539\u001b[0m new_indexes, new_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_indexes_and_vars(obj, matching_indexes)\n\u001b[1;32m    540\u001b[0m dim_pos_indexers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_dim_pos_indexers(matching_indexes)\n\u001b[0;32m--> 542\u001b[0m new_obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_callback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_pos_indexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_variables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    546\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnew_indexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    551\u001b[0m new_obj\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mencoding\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_obj\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/dataarray.py:1771\u001b[0m, in \u001b[0;36mDataArray._reindex_callback\u001b[0;34m(self, aligner, dim_pos_indexers, variables, indexes, fill_value, exclude_dims, exclude_vars)\u001b[0m\n\u001b[1;32m   1768\u001b[0m         fill_value[_THIS_ARRAY] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m   1770\u001b[0m ds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_temp_dataset()\n\u001b[0;32m-> 1771\u001b[0m reindexed \u001b[38;5;241m=\u001b[39m \u001b[43mds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_callback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1772\u001b[0m \u001b[43m    \u001b[49m\u001b[43maligner\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdim_pos_indexers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindexes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexclude_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_temp_dataset(reindexed)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/dataset.py:2834\u001b[0m, in \u001b[0;36mDataset._reindex_callback\u001b[0;34m(self, aligner, dim_pos_indexers, variables, indexes, fill_value, exclude_dims, exclude_vars)\u001b[0m\n\u001b[1;32m   2832\u001b[0m         reindexed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_overwrite_indexes(new_indexes, new_variables)\n\u001b[1;32m   2833\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2834\u001b[0m         reindexed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maligner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2835\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2836\u001b[0m     to_reindex \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   2837\u001b[0m         k: v\n\u001b[1;32m   2838\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   2839\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m variables \u001b[38;5;129;01mand\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m exclude_vars\n\u001b[1;32m   2840\u001b[0m     }\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/dataset.py:1236\u001b[0m, in \u001b[0;36mDataset.copy\u001b[0;34m(self, deep, data)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\n\u001b[1;32m   1138\u001b[0m     \u001b[38;5;28mself\u001b[39m: T_Dataset, deep: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, data: Mapping[Any, ArrayLike] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T_Dataset:\n\u001b[1;32m   1140\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a copy of this dataset.\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m \n\u001b[1;32m   1142\u001b[0m \u001b[38;5;124;03m    If `deep=True`, a deep copy is made of each of the component variables.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[38;5;124;03m    pandas.DataFrame.copy\u001b[39;00m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/dataset.py:1265\u001b[0m, in \u001b[0;36mDataset._copy\u001b[0;34m(self, deep, data, memo)\u001b[0m\n\u001b[1;32m   1259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys_missing_from_data:\n\u001b[1;32m   1260\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1261\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData must contain all variables in original \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1262\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset. Data is missing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(keys_missing_from_data)\n\u001b[1;32m   1263\u001b[0m         )\n\u001b[0;32m-> 1265\u001b[0m indexes, index_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxindexes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_indexes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1267\u001b[0m variables \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1268\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variables\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/indexes.py:1297\u001b[0m, in \u001b[0;36mIndexes.copy_indexes\u001b[0;34m(self, deep, memo)\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1295\u001b[0m     convert_new_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1297\u001b[0m new_idx \u001b[38;5;241m=\u001b[39m \u001b[43midx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_copy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1298\u001b[0m idx_vars \u001b[38;5;241m=\u001b[39m idx\u001b[38;5;241m.\u001b[39mcreate_variables(coords)\n\u001b[1;32m   1300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_new_idx:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/indexes.py:542\u001b[0m, in \u001b[0;36mPandasIndex._copy\u001b[0;34m(self, deep, memo)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    540\u001b[0m     \u001b[38;5;66;03m# index will be copied in constructor\u001b[39;00m\n\u001b[1;32m    541\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m--> 542\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_replace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/indexes.py:300\u001b[0m, in \u001b[0;36mPandasIndex._replace\u001b[0;34m(self, index, dim, coord_dtype)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m coord_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     coord_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoord_dtype\n\u001b[0;32m--> 300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoord_dtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/xarray/core/indexes.py:283\u001b[0m, in \u001b[0;36mPandasIndex.__init__\u001b[0;34m(self, array, dim, coord_dtype)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, array: Any, dim: Hashable, coord_dtype: Any \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;66;03m# make a shallow copy: cheap and because the index name may be updated\u001b[39;00m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;66;03m# here or in other constructors (cannot use pd.Index.rename as this\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;66;03m# constructor is also called from PandasMultiIndex)\u001b[39;00m\n\u001b[0;32m--> 283\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[43msafe_cast_to_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index\u001b[38;5;241m.\u001b[39mname \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    286\u001b[0m         index\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m dim\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/pandas/core/indexes/base.py:1314\u001b[0m, in \u001b[0;36mIndex.copy\u001b[0;34m(self, name, deep, dtype, names)\u001b[0m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m names \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter names is deprecated and will be removed in a future \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1309\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mversion. Use the name parameter instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1310\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m   1311\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m   1312\u001b[0m     )\n\u001b[0;32m-> 1314\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m   1316\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/pandas/core/indexes/base.py:1781\u001b[0m, in \u001b[0;36mIndex._validate_names\u001b[0;34m(self, name, names, deep)\u001b[0m\n\u001b[1;32m   1776\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1777\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of new names must be \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(new_names)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1778\u001b[0m     )\n\u001b[1;32m   1780\u001b[0m \u001b[38;5;66;03m# All items in 'new_names' need to be hashable\u001b[39;00m\n\u001b[0;32m-> 1781\u001b[0m \u001b[43mvalidate_all_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnew_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1783\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_names\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1744\u001b[0m, in \u001b[0;36mvalidate_all_hashable\u001b[0;34m(error_name, *args)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_all_hashable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, error_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mall\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mis_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m error_name:\n\u001b[1;32m   1746\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a hashable type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/pandas/core/dtypes/common.py:1744\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1725\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvalidate_all_hashable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, error_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1726\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1727\u001b[0m \u001b[38;5;124;03m    Return None if all args are hashable, else raise a TypeError.\u001b[39;00m\n\u001b[1;32m   1728\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;124;03m    None\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1744\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[43mis_hashable\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m error_name:\n\u001b[1;32m   1746\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be a hashable type\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/fatiando/lib/python3.10/site-packages/pandas/core/dtypes/inference.py:356\u001b[0m, in \u001b[0;36mis_hashable\u001b[0;34m(obj)\u001b[0m\n\u001b[1;32m    348\u001b[0m \u001b[38;5;66;03m# Unfortunately, we can't use isinstance(obj, collections.abc.Hashable),\u001b[39;00m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# which can be faster than calling hash. That is because numpy scalars\u001b[39;00m\n\u001b[1;32m    350\u001b[0m \u001b[38;5;66;03m# fail this test.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# Reconsider this decision once this numpy bug is fixed:\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# https://github.com/numpy/numpy/issues/5562\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 356\u001b[0m     \u001b[38;5;28;43mhash\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#vfsa\n",
    "\n",
    "def T(kt, c, T0): #Temperature function - kt is iteration of temperature cooling, c is rate of cooling, T0 is starting temp (0-1)\n",
    "    T = np.exp(-c*kt)*T0\n",
    "    return T\n",
    "\n",
    "model_runs = 1000 #max number of model runs\n",
    "n_iterations = 1000#5000 # max number of iterations at each temperature\n",
    "max_accepts = 500#1000 #max number of acceptances before moving on to next temperature\n",
    "max_it_attempts = 200 #max number of times model will try to find updated model within max/min bounds before restarting iteration\n",
    "reject_timeout = 60*15 #if this a model hasn't been accepted for 60 minutes exit model run\n",
    "write_time_start = time.time() #start the timer for writing out the results\n",
    "write_timeout = 30*1 #how often to write results - in seconds\n",
    "\n",
    "M_start = model(param_start)\n",
    "E_start = misfit(g_meas_c10, M_start)\n",
    "\n",
    "inversion_misfits = [E_start] \n",
    "inversion_temp = [0]\n",
    "inversion_results = M_start\n",
    "inversion_parameters = param_start.copy()\n",
    "\n",
    "\n",
    "mi_len = 3 #define number of closest points to include when assessing misfit over pertub area -- could also be a distance?\n",
    "dist_perturb = 500 #distance within which to include points to perturb - relative to randomly chosen perturb points\n",
    "dist_smooth = 750\n",
    "param_weight_avg = np.array([4, 1, 1, 1])\n",
    "param_weight_dists = np.array([0, 200, 400, 760 ])\n",
    "weight_avg_fn = interp1d(param_weight_dists, param_weight_avg)\n",
    "\n",
    "i_low = 8\n",
    "i_up = -10\n",
    "\n",
    "start_time = time.time()\n",
    "tol_time = np.array([0, 0])\n",
    "\n",
    "while tol_time[1] <= 100:\n",
    "\n",
    "    M_old = np.copy(M_start) # define M_old and E_old - which will be updated as model run proceeds\n",
    "    E_old = E_start\n",
    "    params_old = param_start.copy() # define parameter dictionary for pertubation\n",
    "    params_smoothed = param_start.copy() # define parameter dictionary for pertubation\n",
    "\n",
    "    tol = 0 #set tolerance flag to 0\n",
    "    t=0 #set temperature iteration to 0\n",
    "    accept_time = time.time() #reset this with model run so clock starts over\n",
    " \n",
    "    while time.time() < (accept_time + reject_timeout): #while a new model had been accepted in less than timeout\n",
    "        # print ('t= ' + str(t)) #write the temperature\n",
    "        temp_perturb = T(t, 0.25, 0.5) #temperature based on number of temp iterations and parameters\n",
    "        temp_accept = T(t, 0.5, 0.1) #temperature based on number of temp iterations and parameters\n",
    "        if tol == 1: #break out of model run if tolerance has been reached\n",
    "            break\n",
    "        i=0 #for start of each temperature reset i count to 0\n",
    "        num_accept=0 #reset number of acceptances for each new temperature\n",
    "\n",
    "        while i <= n_iterations and num_accept <= max_accepts and time.time() < (accept_time + reject_timeout): #continue to iterate at this temperature until either max iterations has been reached, max acceptances has been reached or no new models have been accepted under timeout\n",
    "\n",
    "            perturb_points = dist_points.iloc[i_low:i_up].copy() #make a copy so not alterning dist points\n",
    "            pi = np.random.choice(len(perturb_points)) #randomly select point to pertub it and the values around it\n",
    "            meas_points['dist_pi'] = np.sqrt((perturb_points['xcoord'].iloc[pi] - meas_points['x_8N'])**2 + (perturb_points['ycoord'].iloc[pi] - meas_points['y_8N'])**2)\n",
    "            meas_points = meas_points.sort_values(by='dist_pi')\n",
    "            mp_i = meas_points.index[:mi_len] #take the 5 closest points -- could also change to taking closes points by distance\n",
    "            E_old = misfit(g_meas_c10[mp_i], M_old[mp_i]) #calculate old error for this section\n",
    "            if E_old >= tolerance:# and pi != p4_id:\n",
    "                params_new = params_old.copy()\n",
    "                perturb_points['dist_pi'] = np.sqrt((perturb_points['xcoord'].iloc[pi] - perturb_points['xcoord'])**2 + (perturb_points['ycoord'].iloc[pi] - perturb_points['ycoord'])**2)\n",
    "                pi_i = perturb_points.index[perturb_points['dist_pi'] <= dist_perturb] #take the points within the perturb distance\n",
    "                for p in pi_i:\n",
    "\n",
    "                    it_attempt=0 #count for how many times value has tried to be updated\n",
    "                    accept_param = 0\n",
    "                    while it_attempt < max_it_attempts and accept_param==0:\n",
    "                        ui = np.random.uniform(0,1) #select random number from uniform distribution\n",
    "                        yi = np.sign(ui - 0.5) * temp_perturb*((1 + (1/temp_perturb))**(abs(2*ui - 1)) - 1) #dervie altertation term based on random number and temperature\n",
    "                        point_pert = yi*(p_max[p] - p_min[p])\n",
    "                        pi_new = params_new[p] + point_pert#get new value for parameter based on max/min allowed values and previous iteration\n",
    "                        it_attempt += 1\n",
    "                        if pi_new <= p_max[p] and pi_new >= p_min[p]:\n",
    "                            params_new[p] = pi_new\n",
    "                            accept_param = 1\n",
    "                \n",
    "                params_smoothed = np.copy(params_new) #copy to apply weighting function\n",
    "                smooth_df = dist_points.iloc[i_low:i_up].copy() #make a copy so not alter dist df\n",
    "                for p in pi_i:\n",
    "                    # if p != p4_id:\n",
    "                    smooth_df['dist_pi'] = np.sqrt((smooth_df['distance'].loc[p] - smooth_df['distance'])**2)\n",
    "                    si = smooth_df.index[smooth_df['dist_pi'] <= dist_smooth]\n",
    "                    weighting = weight_avg_fn(smooth_df.loc[si.values]['dist_pi'])\n",
    "                    weighted_pnts = np.dot(params_new[si], weighting) #multiply selected points by their weighting\n",
    "                    point_avg = np.sum(weighted_pnts)/np.sum(weighting) #divide sum of weighted points by weighting\n",
    "                    params_smoothed[p] = point_avg\n",
    "                params_smoothed[:i_low] = params_smoothed[i_low]\n",
    "                params_smoothed[i_up:] = params_smoothed[i_up-1]\n",
    "\n",
    "            accept = 0 #reset acceptance flag\n",
    "            M_new = model(params_smoothed) #calulate anomaly with new parameter values\n",
    "            E_new = misfit(g_meas_c10[mp_i], M_new[mp_i]) #calculate new error\n",
    "            delta_E = E_new - E_old #check compared to old error\n",
    "            if delta_E < 0: #if new error smaller accept new model\n",
    "                accept = 1\n",
    "                    \n",
    "            if delta_E >= 0:\n",
    "                P = np.exp(-delta_E/temp_accept) #otherwise calculate probability based on error difference and temp\n",
    "                r = np.random.uniform(0,1)\n",
    "                if P>r: #if probability greater than random number accept new model -- but don't update error as it is not new lowest\n",
    "                    accept = 1\n",
    "\n",
    "            if accept == 1:\n",
    "                params_old = params_smoothed.copy() #update parameters to these new ones\n",
    "                E_old = E_new.copy()\n",
    "                M_old = np.copy(M_new) # model becomes old model\n",
    "                accept_time = time.time() #reset time since last acceptance\n",
    "                num_accept += 1 #add to number of acceptances at this temperature\n",
    "                E_all = misfit(g_meas_c10, M_new) # calculate misfit over whole model - this will be used for tolerance\n",
    "                \n",
    "                if E_all < tolerance:\n",
    "                    tol = 1\n",
    "                    # print ('tolerance reached', t, i)\n",
    "                    tol_time[0] = time.time() - start_time\n",
    "                    tol_time[1] = tol_time[1] + 1\n",
    "\n",
    "                    inversion_results = np.vstack((inversion_results, M_old))\n",
    "                    inversion_misfits.append(E_all)\n",
    "                    inversion_temp.append(t)\n",
    "                    inversion_parameters = np.vstack((inversion_parameters, params_old))\n",
    "\n",
    "                    np.savetxt('inversion_results/3Dmisfit.csv', inversion_misfits, delimiter=\",\")\n",
    "                    np.savetxt('inversion_results/3Dtemp.csv', inversion_temp, delimiter=\",\")\n",
    "                    np.savetxt('inversion_results/3Dresult.csv', inversion_results, delimiter=\",\")\n",
    "                    np.savetxt('inversion_results/3Dparam.csv', inversion_parameters, delimiter=\",\")\n",
    "                    np.savetxt('inversion_results/tol_time.csv', tol_time, delimiter=',')\n",
    "\n",
    "                    break\n",
    "            i+=1 #increase count for number of iterations\n",
    "\n",
    "        t+=1\n",
    "        if tol == 1:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_dist(x):\n",
    "    mean = np.mean(x)\n",
    "    sd = np.std(x)\n",
    "    # prob_density = (np.pi*sd) * np.exp(-0.5*((x-mean)/sd)**2)\n",
    "    return mean, sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inversion_filt = [i for i, x in enumerate(inversion_misfits) if x <= tolerance+0.02]\n",
    "inversion_filt = inversion_filt[:100]\n",
    "all_models_filt = inversion_parameters[inversion_filt, :]\n",
    "all_results_filt = inversion_results[inversion_filt, :]\n",
    "\n",
    "means = np.zeros(len(all_models_filt[1,:]))\n",
    "sds = np.zeros(len(all_models_filt[1,:]))\n",
    "means_grav = np.zeros(len(all_results_filt[1,:]))\n",
    "sds_grav = np.zeros(len(all_results_filt[1,:]))\n",
    "for i in range(len(all_models_filt[1,:])):\n",
    "    means[i], sds[i] = normal_dist(all_models_filt[:, i])\n",
    "for i in range(len(all_results_filt[1,:])):\n",
    "    means_grav[i], sds_grav[i] = normal_dist(all_results_filt[:, i])\n",
    "\n",
    "final_model = model(means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(all_models_filt)):\n",
    "    model_xr = surf_inside.copy()\n",
    "    means_norm = all_models_filt[j]/dist_points['thick_norm']\n",
    "    for i in range(len(dist_points)):\n",
    "        dist_band = dist_points['distance'].iloc[i]\n",
    "        model_xr = model_xr.where(dist_xr != dist_band, thick_normal_xr*means_norm[i])\n",
    "    #final edit to make sure areas outside polygon are set to 0 thickness\n",
    "    model_xr = model_xr.where(mask_geom_small == True, 0)\n",
    "    model_xr = model_xr.where(mask_rock_small == False, 0)\n",
    "\n",
    "    prisms_glacier = hm.prism_layer(\n",
    "        (model_xr.x.values, model_xr.y.values),\n",
    "        surface=surf_inside - model_xr,\n",
    "        reference=surf_inside,\n",
    "        properties={\"density\": density_model},\n",
    "    )\n",
    "    \n",
    "    profile4_g = prisms_glacier.prism_layer.gravity((profile4['x_8N'], profile4['y_8N'], profile4['Elev']), field=\"g_z\")\n",
    "    profile7a_g = prisms_glacier.prism_layer.gravity((profile7a['x_8N'], profile7a['y_8N'], profile7a['Elev']), field=\"g_z\")\n",
    "    profile4_anom = (profile4_g - profile4_g[0]) + (profile4['outer_grav'] -  profile4['outer_grav'].iloc[0])\n",
    "    profile7a_anom = (profile7a_g - profile4_g[0]) + (profile7a['outer_grav'] -  profile4['outer_grav'].iloc[0])\n",
    "\n",
    "    thick_spline = RectBivariateSpline(model_xr.y, model_xr.x, model_xr.values)\n",
    "\n",
    "    profile4_thick = np.empty_like(profile4_anom)\n",
    "    for k in range(len(profile4_thick)):\n",
    "        profile4_thick[k] = thick_spline(profile4.loc[k, 'y_8N'],profile4.loc[k,'x_8N'])[0][0]\n",
    "    profile7a_thick = np.empty_like(profile7a_anom)\n",
    "    for k in range(len(profile7a_thick)):\n",
    "        profile7a_thick[k] = thick_spline(profile7a.loc[k, 'y_8N'],profile7a.loc[k,'x_8N'])[0][0]\n",
    "    longa_thick = np.empty_like(longa.dist.to_numpy())\n",
    "    for k in range(len(longa_thick)):\n",
    "        longa_thick[k] = thick_spline(longa.loc[k, 'y_8N'],longa.loc[k,'x_8N'])[0][0]\n",
    "\n",
    "    if j==0:\n",
    "        p4_all_thick = profile4_thick\n",
    "        p7a_all_thick = profile7a_thick\n",
    "        longa_all_thick = longa_thick\n",
    "        p4_all_grav = profile4_anom\n",
    "        p7a_all_grav = profile7a_anom\n",
    "    else:\n",
    "        p4_all_thick = np.vstack((p4_all_thick, profile4_thick))\n",
    "        p7a_all_thick = np.vstack((p7a_all_thick, profile7a_thick))\n",
    "        longa_all_thick = np.vstack((longa_all_thick, longa_thick))\n",
    "        p4_all_grav = np.vstack((p4_all_grav, profile4_anom))\n",
    "        p7a_all_grav = np.vstack((p7a_all_grav, profile7a_anom))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "means_p4_g = np.zeros(len(p4_all_grav[1,:]))\n",
    "sds_p4_g = np.zeros(len(p4_all_grav[1,:]))\n",
    "means_p4_t = np.zeros(len(p4_all_thick[1,:]))\n",
    "sds_p4_t = np.zeros(len(p4_all_thick[1,:]))\n",
    "for i in range(len(p4_all_grav[1,:])):\n",
    "    means_p4_g[i], sds_p4_g[i] = normal_dist(p4_all_grav[:, i])\n",
    "    means_p4_t[i], sds_p4_t[i] = normal_dist(p4_all_thick[:, i])\n",
    "\n",
    "means_p7a_g = np.zeros(len(p7a_all_grav[1,:]))\n",
    "sds_p7a_g = np.zeros(len(p7a_all_grav[1,:]))\n",
    "means_p7a_t = np.zeros(len(p7a_all_thick[1,:]))\n",
    "sds_p7a_t = np.zeros(len(p7a_all_thick[1,:]))\n",
    "for i in range(len(p7a_all_grav[1,:])):\n",
    "    means_p7a_g[i], sds_p7a_g[i] = normal_dist(p7a_all_grav[:, i])\n",
    "    means_p7a_t[i], sds_p7a_t[i] = normal_dist(p7a_all_thick[:, i])\n",
    "\n",
    "means_la_t = np.zeros(len(longa_all_thick[1,:]))\n",
    "sds_la_t = np.zeros(len(longa_all_thick[1,:]))\n",
    "for i in range(len(longa_all_thick[1,:])):\n",
    "    means_la_t[i], sds_la_t[i] = normal_dist(longa_all_thick[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xr = surf_inside.copy()\n",
    "means_norm = means/dist_points['thick_norm']\n",
    "for i in range(len(dist_points)):\n",
    "    dist_band = dist_points['distance'].iloc[i]\n",
    "    params_xr = params_xr.where(dist_xr != dist_band, thick_normal_xr*means_norm[i])\n",
    "#final edit to make sure areas outside polygon are set to 0 thickness\n",
    "params_xr = params_xr.where(mask_geom_small == True, 0)\n",
    "params_xr = params_xr.where(mask_rock_small == False, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save results\n",
    "params_xr.rio.write_crs(26908, inplace=True)\n",
    "\n",
    "dist_points['means'] = means\n",
    "dist_points['sds'] = sds\n",
    "longa[['grav_mean', 'mean_model_grav', 'grav_sd', 'thick_mean', 'thick_sd']] = np.c_[means_grav, final_model, sds_grav, means_la_t, sds_la_t]\n",
    "profile4[['grav_mean', 'grav_sd', 'thick_mean', 'thick_sd']] = np.c_[means_p4_g, sds_p4_g, means_p4_t, sds_p4_t]\n",
    "profile7a[['grav_mean', 'grav_sd', 'thick_mean', 'thick_sd']] = np.c_[means_p7a_g, sds_p7a_g, means_p7a_t, sds_p7a_t]\n",
    "\n",
    "params_xr.rio.to_raster('Results/wide_U_shape/final_thick_xr.tif')\n",
    "dist_points.to_csv('Results/wide_U_shape/dist_points_res.csv', index=False)\n",
    "longa.to_csv('Results/wide_U_shape/longa_grav_res.csv', index=False)\n",
    "profile4.to_csv('Results/wide_U_shape/profile4_grav_res.csv', index=False)\n",
    "profile7a.to_csv('Results/wide_U_shape/profile7a_grav_res.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5e680212d2c5842032ddd0bb4aa6aeee0e7da853b3ca34712facc6e4cee8989c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.2 ('simpeg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
